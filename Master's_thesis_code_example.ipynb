{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Finetuning GPT2**"
      ],
      "metadata": {
        "id": "6yfH7e-k3qM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import argparse\n",
        "import os\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers/\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "qDUGKGXy3r6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=88888)\n",
        "parser.add_argument(\"--model_name\", default=\"gpt2-medium\", type=str)\n",
        "parser.add_argument(\"--max_seq_length\", default=512, type=int)\n",
        "parser.add_argument(\"--train_batch_size\", default=4, type=int)\n",
        "parser.add_argument(\"--valid_batch_size\", default=4, type=int)\n",
        "parser.add_argument(\"--num_train_epochs\", default=4, type=int)\n",
        "parser.add_argument(\"--warmup\", default=0.1, type=float)\n",
        "parser.add_argument(\"--learning_rate\", default=5e-5, type=float)\n",
        "\n",
        "args, _ = parser.parse_known_args()"
      ],
      "metadata": {
        "id": "bwMgsKUkeQWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "excel_file = '/content/IDEST_database.xlsx'\n",
        "idest_df = pd.read_excel(excel_file)\n",
        "selected_cols = ['text_english', 'tags']\n",
        "df_selected = idest_df[selected_cols]\n",
        "df_selected['tags'] = df_selected['tags'].str.replace(';', ' and')\n",
        "df_selected"
      ],
      "metadata": {
        "id": "fPCPwTAReQZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combinetext(prompt, story):\n",
        "    prompts=prompt\n",
        "    stories=story\n",
        "    assert len(prompts)==len(stories)\n",
        "    combine=[]\n",
        "    for i in range(len(prompts)):\n",
        "        combine.append('From the first-person perspective, write an emotional narrative with maximum 200 words about: ' + prompts[i].rstrip()+' <sep> '+\" \".join(stories[i].split()[:300]))\n",
        "    return combine\n",
        "\n",
        "def cleanpunctuation(s):\n",
        "    s=s.replace(' '+'n\\'t','n\\'t')\n",
        "    s=s.replace(' '+'\\'s','\\'s')\n",
        "    s=s.replace(' '+'\\'re','\\'re')\n",
        "    s=s.replace(' '+'\\'ve','\\'ve')\n",
        "    s=s.replace(' '+'\\'ll','\\'ll')\n",
        "    s=s.replace(' '+'\\'am','\\'am')\n",
        "    s=s.replace(' '+'\\'m','\\'m')\n",
        "    s=s.replace(' '+'\\' m','\\'m')\n",
        "    s=s.replace(' '+'\\'m','\\'m')\n",
        "    s=s.replace(' '+'\\' ve','\\'ve')\n",
        "    s=s.replace(' '+'\\' s','\\'s')\n",
        "    s=s.replace('<newline>','\\n')\n",
        "    return s"
      ],
      "metadata": {
        "id": "fNZ9ollYeZed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullData=combinetext(df_selected['tags'], df_selected['text_english'])\n",
        "fullData=list(map(cleanpunctuation,fullData))"
      ],
      "metadata": {
        "id": "Fk1j8DUDeZh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullData"
      ],
      "metadata": {
        "id": "98bq3aTTrKSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "tokenizer.pad_token=tokenizer.eos_token\n",
        "def create_labels(inputs):\n",
        "    labels=[]\n",
        "    for ids,attention_mask in zip(inputs['input_ids'],inputs['attention_mask']):\n",
        "        label=ids.copy()\n",
        "        real_len=sum(attention_mask)\n",
        "        padding_len=len(attention_mask)-sum(attention_mask)\n",
        "        label[:]=label[:real_len]+[-100]*padding_len\n",
        "        labels.append(label)\n",
        "    inputs['labels']=labels\n"
      ],
      "metadata": {
        "id": "x0HIX8LafDUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryDataset:\n",
        "    def __init__(self, inputs):\n",
        "        self.ids = inputs['input_ids']\n",
        "        self.attention_mask = inputs['attention_mask']\n",
        "        self.labels=inputs['labels']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "\n",
        "        return [torch.tensor(self.ids[item], dtype=torch.long),\n",
        "                torch.tensor(self.attention_mask[item], dtype=torch.long),\n",
        "                torch.tensor(self.labels[item], dtype=torch.long)]"
      ],
      "metadata": {
        "id": "ARi9xS2ZfDXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_epochs = args.num_train_epochs\n",
        "\n",
        "weight_decay=0\n",
        "learning_rate=args.learning_rate\n",
        "adam_epsilon=1e-8\n",
        "warmup_steps=500\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": weight_decay,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)"
      ],
      "metadata": {
        "id": "uwIk4ss1fURg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"***** Running training *****\")\n",
        "#print(\"  Total_num_training_step = {}\".format(total_num_training_steps))\n",
        "print(\"  Num Epochs = {}\".format(num_train_epochs))\n",
        "#print(f\"  Train_batch_size per device = {train_batch_size}\")\n",
        "#print(f\"  Valid_batch_size per device = {valid_batch_size}\")\n",
        "model.to('cuda')\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(fullData)):\n",
        "  # Print the current fold number\n",
        "  print(f\"Fold {fold+1}/5\")\n",
        "  print(type(train_idx))\n",
        "  print(type(fullData))\n",
        "  train_text = [fullData[i] for i in train_idx]\n",
        "  valid_text = [fullData[i] for i in val_idx]\n",
        "\n",
        "  inputs_train = tokenizer(train_text, padding=True,truncation=True,max_length=args.max_seq_length)\n",
        "  inputs_valid=tokenizer(valid_text, padding=True,truncation=True,max_length=args.max_seq_length)\n",
        "\n",
        "  create_labels(inputs_train)\n",
        "  create_labels(inputs_valid)\n",
        "  train_batch_size=args.train_batch_size\n",
        "  valid_batch_size=args.valid_batch_size\n",
        "  traindata=StoryDataset(inputs_train)\n",
        "  train_dataloader = torch.utils.data.DataLoader(\n",
        "    traindata,\n",
        "    shuffle=False,\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "  validdata=StoryDataset(inputs_valid)\n",
        "  valid_dataloader = torch.utils.data.DataLoader(\n",
        "    validdata,\n",
        "    shuffle=False,\n",
        "    batch_size=valid_batch_size)\n",
        "  training_steps_per_epoch=len(train_dataloader)\n",
        "  total_num_training_steps = int(training_steps_per_epoch*num_train_epochs)\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_num_training_steps\n",
        "  )\n",
        "\n",
        "  for epoch in range(num_train_epochs):\n",
        "      print(f\"Start epoch{epoch+1} of {num_train_epochs}\")\n",
        "      train_loss=0\n",
        "      epoch_iterator = tqdm(train_dataloader,desc='Iteration')\n",
        "      model.train()\n",
        "      model.zero_grad()\n",
        "      for _, inputs in enumerate(epoch_iterator):\n",
        "          d1,d2,d3=inputs\n",
        "          d1=d1.to('cuda')\n",
        "          d2=d2.to('cuda')\n",
        "          d3=d3.to('cuda')\n",
        "          output = model(input_ids=d1, attention_mask=d2,labels=d3)\n",
        "          batch_loss=output[0]\n",
        "          batch_loss.backward()\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "          model.zero_grad()\n",
        "          train_loss+=batch_loss.item()\n",
        "          epoch_iterator.set_description('(batch loss=%g)' % batch_loss.item())\n",
        "          del batch_loss\n",
        "      print(f'Average train loss per example={train_loss/training_steps_per_epoch} in epoch{epoch+1}')\n",
        "      print(f'Starting evaluate after epoch {epoch+1}')\n",
        "      eval_loss=[]\n",
        "      model.eval()\n",
        "      for inputs in tqdm(valid_dataloader, desc=\"eval\"):\n",
        "          d1,d2,d3=inputs\n",
        "          d1=d1.to('cuda')\n",
        "          d2=d2.to('cuda')\n",
        "          d3=d3.to('cuda')\n",
        "          with torch.no_grad():\n",
        "              output = model(input_ids=d1, attention_mask=d2,labels=d3)\n",
        "              batch_loss=output[0]\n",
        "          eval_loss+=[batch_loss.cpu().item()]\n",
        "          del batch_loss\n",
        "      eval_loss=np.mean(eval_loss)\n",
        "      perplexity=math.exp(eval_loss)\n",
        "      print(f'Average valid loss per example={eval_loss} in epoch{epoch+1}')\n",
        "      print(f'Perplextiy for valid dataset in epoch{epoch+1} is {perplexity}')"
      ],
      "metadata": {
        "id": "TA9J_fJYfUfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(prompt,target,k=0,p=0.9,output_length=200,temperature=0.7,num_return_sequences=3,repetition_penalty=1.0):\n",
        "    print(\"====prompt====\\n\")\n",
        "    print(prompt+\"\\n\")\n",
        "    print('====target story is as below===\\n')\n",
        "    print(target+\"\\n\")\n",
        "    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    output_sequences = model.generate(\n",
        "        input_ids=encoded_prompt,\n",
        "        max_length=output_length,\n",
        "        temperature=temperature,\n",
        "        top_k=k,\n",
        "        top_p=p,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=num_return_sequences\n",
        "    )\n",
        "    if len(output_sequences.shape) > 2:\n",
        "        output_sequences.squeeze_()\n",
        "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "        print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
        "        generated_sequence = generated_sequence.tolist()\n",
        "        # Decode text\n",
        "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
        "        # Remove all text after eos token\n",
        "        text = text[: text.find(tokenizer.eos_token)]\n",
        "        print(text)\n"
      ],
      "metadata": {
        "id": "PQJpA9ZSffYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt='From the first-person perspective, write an emotional narrative with maximum 200 words about: planets'\n",
        "target=fullData[118][fullData[118].find('<sep>')+5:]\n",
        "generate_story(prompt,target)"
      ],
      "metadata": {
        "id": "6U-gQkugfjQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story_inportmodel(prompt,k=0,p=0.9,output_length=219,temperature=0.7,num_return_sequences=1,repetition_penalty=1.0):\n",
        "    print(\"====prompt====\\n\")\n",
        "    print(prompt+\"\\n\")\n",
        "    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    output_sequences = model.generate(\n",
        "        input_ids=encoded_prompt,\n",
        "        max_length=output_length,\n",
        "        temperature=temperature,\n",
        "        top_k=k,\n",
        "        top_p=p,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=num_return_sequences\n",
        "    )\n",
        "    if len(output_sequences.shape) > 2:\n",
        "        output_sequences.squeeze_()\n",
        "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "        print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
        "        generated_sequence = generated_sequence.tolist()\n",
        "        # Decode text\n",
        "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
        "        # Remove all text after eos token\n",
        "        text = text[: text.find(tokenizer.eos_token)]\n",
        "        print(text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "XX_gcs5DjTml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "oM97I0SXjVnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_df = pd.DataFrame(columns=[\"tag\",\"story\"])\n",
        "for tag in tags:\n",
        "#for tag in df_selected['tags']:\n",
        "  prompt='From the first-person perspective, write an emotional narrative with maximum 200 words about: ' + tag\n",
        "  story = generate_story_inportmodel(prompt)\n",
        "  gpt2_df = gpt2_df.append({\"tag\": tag,\"story\": story}, ignore_index=True)\n",
        "\n",
        "# Save the updated DataFrame to the CSV file\n",
        "csv_file_path = \"GPT2-new-finetune.csv\"\n",
        "gpt2_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Download the CSV file to your local machine\n",
        "files.download(csv_file_path)"
      ],
      "metadata": {
        "id": "ZL9vO_XLjVqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the stories by removing the begining sentence of the prompt\n",
        "import re\n",
        "for i, story in enumerate(gpt2_df['story']):\n",
        "  new_story = re.sub(r\".*?<sep>\", \"\", story)\n",
        "  gpt2_df.loc[i, \"story\"] = new_story\n",
        "print(gpt2_df)"
      ],
      "metadata": {
        "id": "eNdqlesctXTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sentiment analysis**"
      ],
      "metadata": {
        "id": "jlvc-SZf4Mra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis with sliding window approach"
      ],
      "metadata": {
        "id": "RqUI6aJJw63d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDEST data example"
      ],
      "metadata": {
        "id": "i3MfPDoWz0QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data preprocessing\n",
        "story = idest_df['text_english']\n",
        "sentiment_map = { 1: 'Constant',  2: 'Tragedy', 3 : 'Rags-to-riches',  4 : 'Man-in-a-hole ',  5 :'Icarus',  6 : 'Oedipus',  7 : 'Cinderella', 8 : 'No clear story' }\n",
        "# Reverse the key-value pairs in the dictionary\n",
        "sentiment_map = {str(key): value for key, value in sentiment_map.items()}\n",
        "idest_df['StoryType'] = idest_df['StoryType'].astype(str).replace(sentiment_map)\n",
        "\n",
        "#tokenize the stories using NLTK\n",
        "import nltk\n",
        "stories = []\n",
        "input_sentences = []\n",
        "nltk.download('punkt')\n",
        "\n",
        "for item in story:\n",
        "  stories.append(item)\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "for story in stories:\n",
        "  input_sentences.append(sent_tokenize(story))"
      ],
      "metadata": {
        "id": "w_Aza5KY75jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sentiment analysis using the sliding window approach\n",
        "! pip install torch\n",
        "sentiment_data = []\n",
        "\n",
        "# Convert sentences and labels to numpy arrays\n",
        "\n",
        "for story_index, story in enumerate(input_sentences):\n",
        "    sentences = list(story)\n",
        "\n",
        "    # Define window size and stride\n",
        "    window_size = 2\n",
        "    stride = 1\n",
        "\n",
        "    # Create sliding windows of sentences\n",
        "    windows = [sentences[i:i + window_size] for i in range(0, len(sentences) - window_size + 1, stride)]\n",
        "\n",
        "    # Tokenize and encode the windows\n",
        "    encoded_windows = []\n",
        "    for window in windows:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            window,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        encoded_windows.append(encoded)\n",
        "\n",
        "    # Perform inference on the windows\n",
        "    model.eval()\n",
        "    sentiment_labels = []\n",
        "    sentiment_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for encoded_window in encoded_windows:\n",
        "        input_ids = encoded_window['input_ids']\n",
        "        attention_mask = encoded_window['attention_mask']\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predicted_label = torch.argmax(logits).item()\n",
        "\n",
        "        probabilities = torch.softmax(logits, dim=1)\n",
        "        predicted_probability = probabilities[0][1].item()\n",
        "\n",
        "\n",
        "        # Map the predicted label to the corresponding sentiment category\n",
        "        sentiment_labels.append(predicted_label)\n",
        "\n",
        "        # Store the sentiment probability in the list\n",
        "        sentiment_probabilities.append(predicted_probability)\n",
        "\n",
        "    # Store the data in a dictionary\n",
        "    for i, window in enumerate(windows[:min(len(sentiment_labels), len(windows))]):\n",
        "        sentiment_data.append({\n",
        "            'Story': f\"Story {story_index + 1}\",\n",
        "            'Sentences': ' '.join(window),\n",
        "            'Sentiment Label': sentiment_labels[i],\n",
        "            'Sentiment Probability': sentiment_probabilities[i]\n",
        "        })\n",
        "\n",
        "# Convert the data to a pandas DataFrame for tabular representation\n",
        "human_story_sentiment = pd.DataFrame(sentiment_data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(len(human_story_sentiment))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4vp4veu9NHA",
        "outputId": "960c6098-aa40-4b77-de02-e1bad93e199b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Story' and calculate the average 'Sentiment Probability'\n",
        "grouped_human = human_story_sentiment.groupby('Story')['Sentiment Probability'].mean().reset_index()\n",
        "\n",
        "# Set 'Sentiment Label' to 1 if 'Sentiment Probability' is >= 0.5 , 0 otherwise\n",
        "grouped_human['Sentiment Label'] = (grouped_human['Sentiment Probability'] >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "OCbq2lBDwJfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge 'human' with 'grouped_human' based on 'Story' to get 'Sentiment Label' information for each story\n",
        "merged_human = human_story_sentiment.merge(grouped_human[['Story', 'Sentiment Label']], on='Story', how='left')\n",
        "\n",
        "# Filter the entries with 'Sentiment Label' equal to 1\n",
        "stories_with_sentiment_label_1 = merged_human[merged_human['Sentiment Label_y'].eq(1)]\n",
        "stories_with_sentiment_label_0 = merged_human[merged_human['Sentiment Label_y'].eq(0)]\n"
      ],
      "metadata": {
        "id": "G4aRyVXRwJig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##positive stories\n",
        "stories_with_sentiment_label_1['Sliding Window'] = stories_with_sentiment_label_1.groupby('Story').cumcount() + 1\n",
        "stories_with_sentiment_label_1"
      ],
      "metadata": {
        "id": "fx2kY9T3AqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group by 'Sliding Window' and calculate the average 'Sentiment Probability' for each window\n",
        "average_probability_by_window = stories_with_sentiment_label_1.groupby('Sliding Window')['Sentiment Probability'].mean()\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(average_probability_by_window.index, average_probability_by_window.values, marker='o', linestyle='-')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Average Sentiment Probability')\n",
        "plt.title('Positive Human Stories - Average Sentiment Probability for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "\n",
        "\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HL1Q8-eLyEhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#negative stories\n",
        "stories_with_sentiment_label_0['Sliding Window'] = stories_with_sentiment_label_0.groupby('Story').cumcount() + 1\n",
        "stories_with_sentiment_label_0"
      ],
      "metadata": {
        "id": "AUB4sioyA5u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Sliding Window' and calculate the average 'Sentiment Probability' for each window\n",
        "average_probability_by_window = stories_with_sentiment_label_0.groupby('Sliding Window')['Sentiment Probability'].mean()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(average_probability_by_window.index, average_probability_by_window.values, marker='o', linestyle='-')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Average Sentiment Probability')\n",
        "plt.title('Negative Human Stories - Average Sentiment Probability for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U9MdNpyXA6HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Sliding Window' and calculate the average 'Sentiment Probability' for each window\n",
        "average_probability_positive = stories_with_sentiment_label_1.groupby('Sliding Window')['Sentiment Probability'].mean()\n",
        "average_probability_negative = stories_with_sentiment_label_0.groupby('Sliding Window')['Sentiment Probability'].mean()\n",
        "\n",
        "# Plot with two subplots side by side\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Plot for positive stories\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(average_probability_positive.index, average_probability_positive.values, marker='o', linestyle='-',color='blue')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Average Sentiment Probability')\n",
        "plt.title('Positive Human Stories - Average Sentiment Probability for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "# Plot for negative stories\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(average_probability_negative.index, average_probability_negative.values, marker='o', linestyle='-',color='red')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Average Sentiment Probability')\n",
        "plt.title('Negative Human Stories - Average Sentiment Probability for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1.1)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TpvSxB5lCCfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Sliding Window' and collect the 'Sentiment Probability' for each window as lists\n",
        "data_positive = stories_with_sentiment_label_1.groupby('Sliding Window')['Sentiment Probability'].apply(list)\n",
        "data_negative = stories_with_sentiment_label_0.groupby('Sliding Window')['Sentiment Probability'].apply(list)\n",
        "\n",
        "# Convert the index to a 1-dimensional array using .to_numpy() or .values\n",
        "positions_positive = average_probability_positive.index.to_numpy()\n",
        "positions_negative = average_probability_negative.index.to_numpy()\n",
        "\n",
        "# Create the violin plot for positive stories\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.violinplot(data_positive, positions=positions_positive, showmedians=True, vert=True, widths=0.7, points=100)\n",
        "plt.plot(average_probability_positive.index, average_probability_positive.values, marker='o', linestyle='-', color='blue', label='Average')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Sentiment Probability')\n",
        "plt.title('Positive Human Stories - Sentiment Probability Distribution for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "\n",
        "# Create the violin plot for negative stories\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2 (bottom)\n",
        "plt.violinplot(data_negative, positions=positions_negative, showmedians=True, vert=True, widths=0.7, points=100)\n",
        "plt.plot(average_probability_negative.index, average_probability_negative.values, marker='o', linestyle='-', color='red', label='Average')\n",
        "plt.xlabel('Sliding Window')\n",
        "plt.ylabel('Sentiment Probability')\n",
        "plt.title('Negative Human Stories - Sentiment Probability Distribution for Each Sliding Window')\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1duY3IYhBOs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmGHGiAHD_8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}